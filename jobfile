public long countLines(String filePath) throws IOException {
    try (Stream<String> lines = Files.lines(Paths.get(filePath))) {
        return lines.skip(1).count(); // Skip header
    }
}
@Component
public class LineCountListener implements JobExecutionListener {

    @Value("${input.file}")
    private String inputFile;

    @Override
    public void beforeJob(JobExecution jobExecution) {
        try {
            long count = Files.lines(Paths.get(inputFile)).skip(1).count();
            System.out.println("Total data lines (excluding header): " + count);
            jobExecution.getExecutionContext().putLong("lineCount", count);
        } catch (IOException e) {
            throw new RuntimeException("Failed to count lines", e);
        }
    }

    @Override
    public void afterJob(JobExecution jobExecution) {
        // Optional: compare with processed count
    }
}

package com.example.batch.mapper;

import com.example.batch.domain.MyEntity;
import org.apache.commons.csv.CSVFormat;
import org.apache.commons.csv.CSVParser;
import org.apache.commons.csv.CSVRecord;
import org.springframework.batch.item.file.LineMapper;
import org.springframework.batch.item.file.FlatFileParseException;

import java.io.IOException;
import java.io.StringReader;
import java.util.List;

public class CsvLineMapper implements LineMapper<MyEntity> {

    @Override
    public MyEntity mapLine(String line, int lineNumber) throws Exception {
        String cleanedLine = escapeStrayQuotes(line);
        try (CSVParser parser = CSVFormat.DEFAULT
                .withTrim()
                .withQuote('"')
                .parse(new StringReader(cleanedLine))) {

            List<CSVRecord> records = parser.getRecords();
            if (records.isEmpty()) {
                throw new FlatFileParseException("Empty line at line " + lineNumber, line, lineNumber);
            }

            CSVRecord record = records.get(0);
            MyEntity entity = new MyEntity();
            entity.setId(record.get(0));
            entity.setFirstName(record.get(1));
            entity.setLastName(record.get(2));
            entity.setAddress(record.get(3));
            return entity;
        } catch (IOException | IndexOutOfBoundsException e) {
            throw new FlatFileParseException("Parsing error at line " + lineNumber, line, lineNumber, e);
        }
    }

    private String escapeStrayQuotes(String line) {
        return line.replaceAll("(?<!\")\"(?![\"]|,|\\s*$)", "\"\"");
    }
}

package com.example.batch.processor;

import com.example.batch.domain.MyEntity;
import org.springframework.batch.item.ItemProcessor;

public class MyEntityProcessor implements ItemProcessor<MyEntity, MyEntity> {
    @Override
    public MyEntity process(MyEntity item) {
        // Optional: clean up or validate data
        return item;
    }
}
package com.example.batch.processor;

import com.example.batch.domain.MyEntity;
import org.springframework.batch.item.ItemProcessor;

public class MyEntityProcessor implements ItemProcessor<MyEntity, MyEntity> {
    @Override
    public MyEntity process(MyEntity item) {
        // Optional: clean up or validate data
        return item;
    }
}
package com.example.batch.writer;

import com.example.batch.domain.MyEntity;
import org.springframework.batch.item.ItemWriter;

import java.util.List;

public class MyEntityWriter implements ItemWriter<MyEntity> {
    @Override
    public void write(List<? extends MyEntity> items) {
        items.forEach(System.out::println); // Just log to console for demo
    }
}
package com.example.batch.config;

import com.example.batch.domain.MyEntity;
import com.example.batch.mapper.CsvLineMapper;
import com.example.batch.processor.MyEntityProcessor;
import com.example.batch.writer.MyEntityWriter;
import org.springframework.batch.core.*;
import org.springframework.batch.core.configuration.annotation.*;
import org.springframework.batch.core.launch.support.RunIdIncrementer;
import org.springframework.batch.item.file.FlatFileItemReader;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.*;
import org.springframework.core.io.FileSystemResource;

@Configuration
@EnableBatchProcessing
public class BatchConfig {

    @Bean
    public FlatFileItemReader<MyEntity> reader(@Value("${input.file}") String inputFile) {
        FlatFileItemReader<MyEntity> reader = new FlatFileItemReader<>();
        reader.setResource(new FileSystemResource(inputFile));
        reader.setLineMapper(new CsvLineMapper());
        return reader;
    }

    @Bean
    public MyEntityProcessor processor() {
        return new MyEntityProcessor();
    }

    @Bean
    public MyEntityWriter writer() {
        return new MyEntityWriter();
    }

    @Bean
    public Job importJob(JobBuilderFactory jobs, Step step1) {
        return jobs.get("importJob")
                .incrementer(new RunIdIncrementer())
                .flow(step1)
                .end()
                .build();
    }

    @Bean
    public Step step1(StepBuilderFactory steps, FlatFileItemReader<MyEntity> reader) {
        return steps.get("step1")
                .<MyEntity, MyEntity>chunk(10)
                .reader(reader)
                .processor(processor())
                .writer(writer())
                .build();
    }
}
public long countLines(String filePath) throws IOException {
    try (Stream<String> lines = Files.lines(Paths.get(filePath))) {
        return lines.skip(1).count(); // Skip header
    }
}

@Component
public class LineCountListener implements JobExecutionListener {

    @Value("${input.file}")
    private String inputFile;

    @Override
    public void beforeJob(JobExecution jobExecution) {
        try {
            long count = Files.lines(Paths.get(inputFile)).skip(1).count();
            System.out.println("Total data lines (excluding header): " + count);
            jobExecution.getExecutionContext().putLong("lineCount", count);
        } catch (IOException e) {
            throw new RuntimeException("Failed to count lines", e);
        }
    }

    @Override
    public void afterJob(JobExecution jobExecution) {
        // Optional: compare with processed count
    }
}
@Bean
public Step step1(StepBuilderFactory steps,
                  FlatFileItemReader<MyEntity> reader,
                  MyEntityProcessor processor,
                  MyEntityWriter writer) {
    return steps.get("step1")
            .<MyEntity, MyEntity>chunk(10)
            .reader(reader)
            .processor(processor)
            .writer(writer)
            .listener(new StepExecutionListener() {
                @Override
                public void beforeStep(StepExecution stepExecution) {}

                @Override
                public ExitStatus afterStep(StepExecution stepExecution) {
                    System.out.println("Items read: " + stepExecution.getReadCount());
                    return ExitStatus.COMPLETED;
                }
            })
            .build();
}
jobExecution.getExecutionContext().putLong("lineCount", actualLineCount);
Long count = stepExecution.getJobExecution().getExecutionContext().getLong("lineCount");
